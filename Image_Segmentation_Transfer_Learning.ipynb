{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Image_Segmentation_Transfer_Learning.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hossein-khalilian/Machine-Vision/blob/main/Image_Segmentation_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCSP-dbMw88x"
      },
      "source": [
        "# Image segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVAjHVniItdl"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir(\"/content/drive/My Drive/app/Image_Segmentation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zROT7myDJpIA"
      },
      "source": [
        "# !wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_semantics.zip\n",
        "# !unzip data_semantics.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXyf5qek7M1G"
      },
      "source": [
        "!pip install -q git+https://github.com/tensorflow/examples.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQX7R4bhZy5h"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from IPython.display import clear_output\n",
        "from sklearn.model_selection import train_test_split\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.callbacks import TensorBoard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYTroW_bmgDV"
      },
      "source": [
        "### Import dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "247hWDMM9rdj"
      },
      "source": [
        "sh = (256, 128)\n",
        "x_train = [cv2.resize(cv2.imread(file), dsize=sh) for file in sorted(glob.glob(\"dataset/training/image_2/*.png\"))]\n",
        "x_train = np.array(x_train)/255.0\n",
        "print(x_train.shape)\n",
        "\n",
        "y_train = [cv2.resize(cv2.imread(file), dsize=sh) for file in sorted(glob.glob(\"dataset/training/semantic/*.png\"))]\n",
        "y_train = np.array(y_train)\n",
        "y_train = y_train[:,:,:,0:1]\n",
        "y_train = y_train.astype('uint8')\n",
        "print(y_train.shape)\n",
        "\n",
        "# x_test  = [cv2.resize(cv2.imread(file), dsize=sh) for file in sorted(glob.glob(\"dataset/testing/image_2/*.png\"))]\n",
        "# x_test = np.array(x_test)/255.0\n",
        "# print(x_test.shape)\n",
        "\n",
        "index = np.random.permutation(200)\n",
        "x_train = x_train[index]\n",
        "y_train = y_train[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOfe-UI5bAPJ"
      },
      "source": [
        "### Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jqc0CVLKNKl"
      },
      "source": [
        "BATCH_SIZE = 5\n",
        "BUFFER_SIZE = 200\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((x_valid, y_valid)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoblTjtfavml"
      },
      "source": [
        "input_shape = x_train[0].shape\n",
        "res_net = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "res_net.trainable = False\n",
        "# res_net.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0PE2zucS9C3"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2Ww9oVrhE6X"
      },
      "source": [
        "output_channels = y_train.max()+1\n",
        "sh = x_train[0].shape\n",
        "\n",
        "decoder_input = keras.Input(shape=(4,8,2048))\n",
        "x = decoder_input\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(128, 3, strides=2, padding='same', use_bias=False)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(64, 3, strides=2, padding='same', use_bias=False)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(32, 3, strides=4, padding='same', use_bias=False)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "# x = layers.Conv2DTranspose(64, 3, strides=2, padding='same', use_bias=False)(x)\n",
        "# x = layers.BatchNormalization()(x)\n",
        "# x = layers.LeakyReLU()(x)\n",
        "# x = layers.Dropout(0.3)(x)\n",
        "\n",
        "decoder_output = layers.Conv2DTranspose(output_channels, 3, strides=2, padding='same', use_bias=False, activation='sigmoid')(x)\n",
        "\n",
        "decoder = keras.Model(decoder_input, decoder_output, name='decoder')\n",
        "decoder.summary()\n",
        "\n",
        "\n",
        "\n",
        "autoencoder_input = keras.Input(shape=sh, name='img')\n",
        "encoded_img = res_net(autoencoder_input)\n",
        "decoded_img = decoder(encoded_img)\n",
        "autoencoder = keras.Model(autoencoder_input, decoded_img, name='tl_autoencoder')\n",
        "autoencoder.summary()\n",
        "\n",
        "keras.utils.plot_model(autoencoder, 'my_first_model_with_shape_info.png', show_shapes=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5epDfaOQMq-u"
      },
      "source": [
        "def display(display_list):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for i in range(len(display_list)): \n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.imshow(display_list[i])\n",
        "    plt.show()\n",
        "        \n",
        "\n",
        "def show_predictions():\n",
        "    y_pred = np.argmax(autoencoder(x_train[0:1]), axis=-1)\n",
        "    display([x_train[0], y_train[0,:,:,0], y_pred[0]])\n",
        "\n",
        "\n",
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    if epoch % 5 == 0:\n",
        "        clear_output(wait=True)\n",
        "        show_predictions()\n",
        "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84QNAgPCbZ-b"
      },
      "source": [
        "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gbFkHtrMz0E"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints_image_segmentation_with_transfer_learning'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(model=autoencoder)\n",
        "\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdV_eaNDNNNN"
      },
      "source": [
        "skip_training = False\n",
        "batch_size = 5\n",
        "epochs = 300\n",
        "\n",
        "logdir = './log'+'/transfer_learning'\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "if not skip_training:\n",
        "    model_history = autoencoder.fit(train_dataset, validation_data=valid_dataset,\n",
        "            verbose=True,\n",
        "            epochs=epochs,\n",
        "            callbacks=[DisplayCallback(), tensorboard_callback],\n",
        "            )\n",
        "#     autoencoder.save('autoencoder_image_segmentation.h5') \n",
        "if skip_training:\n",
        "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLEoNNtpSayu"
      },
      "source": [
        "### Fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVf_MZ2IONAZ"
      },
      "source": [
        "res_net.trainable = True\n",
        "print(\"Number of layers in the base model: \", len(res_net.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 150\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in res_net.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43iv8nbPOsrb"
      },
      "source": [
        "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQYtTO-1O1ht"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints_image_segmentation_with_transfer_learning_fine_tune'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(model=autoencoder)\n",
        "\n",
        "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ5HDCtePGtu"
      },
      "source": [
        "skip_training = False\n",
        "batch_size = 5\n",
        "epochs = 300\n",
        "\n",
        "logdir = './log'+'/transfer_learning'\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "if not skip_training:\n",
        "    model_history = autoencoder.fit(train_dataset, validation_data=valid_dataset,\n",
        "            verbose=True,\n",
        "            epochs=epochs,\n",
        "            callbacks=[DisplayCallback(), tensorboard_callback],\n",
        "            )\n",
        "#     autoencoder.save('autoencoder_image_segmentation.h5') \n",
        "if skip_training:\n",
        "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqRf5ZqBPKvS"
      },
      "source": [
        "# print(model_history.history['val_acc'][-1])\n",
        "# print(model_history.history['acc'][-1])\n",
        "print(model_history.history['accuracy'][-1])\n",
        "print(model_history.history['val_accuracy'][-1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}