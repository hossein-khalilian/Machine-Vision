{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Image_Segmentation.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hossein-khalilian/Machine-Vision/blob/main/Image_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCSP-dbMw88x"
      },
      "source": [
        "# Image segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVAjHVniItdl"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir(\"/content/drive/My Drive/app/Image_Segmentation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zROT7myDJpIA"
      },
      "source": [
        "# !wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_semantics.zip\n",
        "# !unzip data_semantics.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQX7R4bhZy5h"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from IPython.display import clear_output\n",
        "from sklearn.model_selection import train_test_split\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.callbacks import TensorBoard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "247hWDMM9rdj"
      },
      "source": [
        "sh = (256, 128)\n",
        "x_train = [cv2.resize(cv2.imread(file), dsize=sh) for file in sorted(glob.glob(\"dataset/training/image_2/*.png\"))]\n",
        "x_train = np.array(x_train)/255.0\n",
        "print(x_train.shape)\n",
        "\n",
        "y_train = [cv2.resize(cv2.imread(file), dsize=sh) for file in sorted(glob.glob(\"dataset/training/semantic/*.png\"))]\n",
        "y_train = np.array(y_train)\n",
        "y_train = y_train[:,:,:,0:1]\n",
        "y_train = y_train.astype('uint8')\n",
        "print(y_train.shape)\n",
        "\n",
        "x_test  = [cv2.resize(cv2.imread(file), dsize=sh) for file in sorted(glob.glob(\"dataset/testing/image_2/*.png\"))]\n",
        "x_test = np.array(x_test)/255.0\n",
        "print(x_test.shape)\n",
        "\n",
        "index = np.random.permutation(200)\n",
        "x_train = x_train[index]\n",
        "y_train = y_train[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhWm16vOY8lk"
      },
      "source": [
        "#Defining the model\n",
        "sh = x_train.shape\n",
        "output_channels = 34\n",
        "\n",
        "encoder_input = keras.Input(shape=(sh[1], sh[2], 3), name='original_img')\n",
        "\n",
        "# x = layers.Conv2D(16, 3, padding='same')(encoder_input)\n",
        "# x = layers.LeakyReLU()(x)\n",
        "# x = layers.MaxPooling2D()(x)\n",
        "# x = layers.Dropout(0.2)(x)\n",
        "\n",
        "x = layers.Conv2D(32, 3, padding='same')(encoder_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "# x = layers.Dropout(0.2)(x)\n",
        "x = layers.GaussianDropout(0.1)(x)\n",
        "\n",
        "x = layers.Conv2D(16, 3, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.MaxPooling2D(4)(x)\n",
        "# x = layers.Dropout(0.2)(x)\n",
        "x = layers.GaussianDropout(0.1)(x)\n",
        "sh1 = x.shape\n",
        "\n",
        "encoder_output = layers.Flatten()(x)\n",
        "encoder_output = layers.Dense(256)(encoder_output)\n",
        "encoder_output = layers.LeakyReLU()(encoder_output)\n",
        "\n",
        "\n",
        "encoder = keras.Model(encoder_input, encoder_output, name='encoder')\n",
        "encoder.summary()\n",
        "\n",
        "decoder_input = keras.Input(shape=256)\n",
        "x = layers.Dense(sh1[1]*sh1[2]*16)(decoder_input)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape((sh1[1], sh1[2], 16))(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(16, 3, strides=4, padding='same', use_bias=False)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(32, 3, strides=2, padding='same', use_bias=False)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "# x = layers.Conv2DTranspose(16, 3, strides=2, padding='same', use_bias=False)(x)\n",
        "# x = layers.BatchNormalization()(x)\n",
        "# x = layers.LeakyReLU()(x)\n",
        "\n",
        "decoder_output = layers.Conv2DTranspose(output_channels, 3, strides=1, padding='same', use_bias=False, activation='sigmoid')(x)\n",
        "\n",
        "\n",
        "decoder = keras.Model(decoder_input, decoder_output, name='decoder')\n",
        "decoder.summary()\n",
        "\n",
        "autoencoder_input = keras.Input(shape=(sh[1], sh[2], 3), name='img')\n",
        "encoded_img = encoder(autoencoder_input)\n",
        "decoded_img = decoder(encoded_img)\n",
        "autoencoder = keras.Model(autoencoder_input, decoded_img, name='autoencoder')\n",
        "autoencoder.summary()\n",
        "\n",
        "keras.utils.plot_model(autoencoder, 'my_first_model_with_shape_info.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orudP1KFg64U"
      },
      "source": [
        "def display(display_list):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for i in range(len(display_list)): \n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.imshow(display_list[i])\n",
        "    plt.show()\n",
        "        \n",
        "\n",
        "def show_predictions():\n",
        "    y_pred = np.argmax(autoencoder(x_train[0:1]), axis=-1)\n",
        "    display([x_train[0], y_train[0,:,:,0], y_pred[0]])\n",
        "\n",
        "\n",
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    if epoch % 10 == 0:\n",
        "        clear_output(wait=True)\n",
        "        show_predictions()\n",
        "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-GT7w9ZRjQL"
      },
      "source": [
        "autoencoder.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI_lh-08mNI0"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints_image_segmentation_with_gausian_dropout50'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(model=autoencoder)\n",
        "\n",
        "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5999uHFjgHk"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adefPGsfQa7G"
      },
      "source": [
        "skip_training = False\n",
        "batch_size = 5\n",
        "epochs = 300\n",
        "\n",
        "logdir = './log'+'/dropout'\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "if not skip_training:\n",
        "    model_history = autoencoder.fit(x_train, y_train, verbose=False,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            callbacks=[DisplayCallback(), tensorboard_callback],\n",
        "            validation_split=0.2,\n",
        "            )\n",
        "#     autoencoder.save('autoencoder_image_segmentation.h5') \n",
        "if skip_training:\n",
        "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sZiFUitxYo8"
      },
      "source": [
        "print(model_history.history['val_acc'][-1])\n",
        "print(model_history.history['acc'][-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiGvhl59QZJj"
      },
      "source": [
        "# autoencoder = tf.keras.models.load_model('autoencoder_image_segmentation_final.h5')\n",
        "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "x_out = autoencoder(x_train[100:110])\n",
        "x_out = np.argmax(x_out, axis=3)\n",
        "for x in x_out:\n",
        "    plt.imshow(x)\n",
        "    plt.show()\n",
        "x_out = autoencoder(x_test[0:5])\n",
        "x_out = np.argmax(x_out, axis=3)\n",
        "for x in x_out:\n",
        "    plt.imshow(x)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiquEUjPNEuu"
      },
      "source": [
        "y_pred = autoencoder(x_train)\n",
        "y_pred = np.argmax(y_pred, axis=3)\n",
        "y1 = y_train[:5].reshape(-1,1)\n",
        "y2 = y_pred[:5].reshape(-1, 1)\n",
        "cnf_matrix = confusion_matrix(y1, y2)\n",
        "np.set_printoptions(linewidth=np.inf)\n",
        "print(cnf_matrix.shape)\n",
        "# print(cnf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2ijKAZnOC92"
      },
      "source": [
        "# ! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "# ! unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgMDFkZYjryp"
      },
      "source": [
        "logdir=\"log\"\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(logdir)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ed8iMXTj8Tg"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55k004ik58jR"
      },
      "source": [
        "# # %load_ext tensorboard \n",
        "# %tensorboard --logdir log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMmKs8FP5lhf"
      },
      "source": [
        "# from tensorboard import notebook\n",
        "# notebook.list() \n",
        "# notebook.display(port=6006, height=2000) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}